#!/usr/bin/env python3

"""
Large Scale Producer Test for FluxMQ
ÎåÄÍ∑úÎ™® ÏÑ±Îä• ÌÖåÏä§Ìä∏
"""

from kafka import KafkaProducer
import time
import json
import threading
from concurrent.futures import ThreadPoolExecutor

def producer_worker(thread_id, messages_per_thread):
    """Í∞úÎ≥Ñ Producer ÏõåÏª§"""
    producer = KafkaProducer(
        bootstrap_servers=['localhost:9092'],
        value_serializer=lambda x: json.dumps(x).encode('utf-8'),
        client_id=f'producer-{thread_id}',
        batch_size=16384,  # Î∞∞Ïπò ÌÅ¨Í∏∞ Ï¶ùÍ∞Ä
        linger_ms=1,       # Î∞∞Ïπò ÎåÄÍ∏∞ ÏãúÍ∞Ñ
        acks=1            # Îπ†Î•∏ ÏùëÎãµÏùÑ ÏúÑÌï¥ acks=1
    )
    
    topic_name = 'test-topic'  # Í∏∞Ï°¥ ÌÜ†ÌîΩ ÏÇ¨Ïö©
    
    start_time = time.time()
    
    for i in range(messages_per_thread):
        message = {
            'thread_id': thread_id,
            'message_id': i,
            'timestamp': time.time(),
            'data': f'thread-{thread_id}-message-{i}'
        }
        producer.send(topic_name, message)
    
    producer.flush()
    producer.close()
    
    end_time = time.time()
    duration = end_time - start_time
    throughput = messages_per_thread / duration
    
    return thread_id, messages_per_thread, duration, throughput

def large_scale_test():
    """ÎåÄÍ∑úÎ™® ÏÑ±Îä• ÌÖåÏä§Ìä∏"""
    print("üöÄ Large Scale Producer Test")
    print("=" * 60)
    
    # ÌÖåÏä§Ìä∏ ÏÑ§Ï†ï
    num_threads = 4        # Producer Ïä§Î†àÎìú Ïàò
    messages_per_thread = 5000  # Ïä§Î†àÎìúÎãπ Î©îÏãúÏßÄ Ïàò
    total_messages = num_threads * messages_per_thread
    
    print(f"Configuration:")
    print(f"  Producer threads: {num_threads}")
    print(f"  Messages per thread: {messages_per_thread:,}")
    print(f"  Total messages: {total_messages:,}")
    print(f"  Target: >400k msg/sec")
    print()
    
    start_time = time.time()
    
    # Î©ÄÌã∞Ïä§Î†àÎìú Producer Ïã§Ìñâ
    with ThreadPoolExecutor(max_workers=num_threads) as executor:
        futures = []
        for thread_id in range(num_threads):
            future = executor.submit(producer_worker, thread_id, messages_per_thread)
            futures.append(future)
        
        print("Running producer threads...")
        results = []
        for future in futures:
            thread_id, messages, duration, throughput = future.result()
            results.append((thread_id, messages, duration, throughput))
            print(f"  Thread {thread_id}: {messages:,} msgs in {duration:.2f}s = {throughput:,.0f} msg/sec")
    
    end_time = time.time()
    total_duration = end_time - start_time
    total_throughput = total_messages / total_duration
    
    # Í≤∞Í≥º Ï∂úÎ†•
    print("\nüìä Results Summary")
    print("=" * 60)
    print(f"Total Messages: {total_messages:,}")
    print(f"Total Duration: {total_duration:.2f} seconds")
    print(f"Overall Throughput: {total_throughput:,.0f} msg/sec")
    
    # Í∞úÎ≥Ñ Ïä§Î†àÎìú ÌÜµÍ≥Ñ
    thread_throughputs = [result[3] for result in results]
    avg_thread_throughput = sum(thread_throughputs) / len(thread_throughputs)
    max_thread_throughput = max(thread_throughputs)
    min_thread_throughput = min(thread_throughputs)
    
    print(f"\nPer-Thread Statistics:")
    print(f"  Average: {avg_thread_throughput:,.0f} msg/sec")
    print(f"  Maximum: {max_thread_throughput:,.0f} msg/sec")
    print(f"  Minimum: {min_thread_throughput:,.0f} msg/sec")
    
    # ÏÑ±Îä• ÌèâÍ∞Ä
    print(f"\nüéØ Performance Assessment:")
    if total_throughput > 400000:
        print(f"  ‚úÖ EXCELLENT: {total_throughput:,.0f} msg/sec > 400k target!")
    elif total_throughput > 100000:
        print(f"  ‚úÖ GOOD: {total_throughput:,.0f} msg/sec > 100k")
    elif total_throughput > 50000:
        print(f"  üî∂ FAIR: {total_throughput:,.0f} msg/sec > 50k")
    else:
        print(f"  ‚ö†Ô∏è NEEDS OPTIMIZATION: {total_throughput:,.0f} msg/sec")
    
    return total_throughput

if __name__ == "__main__":
    large_scale_test()
